{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* In this section, we take a deep dive into details of **backward propagation** also known as **backpropagation**."
      ],
      "metadata": {
        "id": "uHkQ-ZLdNd2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Forward Propagation."
      ],
      "metadata": {
        "id": "HRKxCps7N1Bt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **forward propagation** is the calculation and storage of intermediate variables for a neural network in order from the input layer to the output layer.\n",
        "\n",
        "* Let's assume that the input example is **x** and that our hidden layers does not include a bias term.\n",
        "* Here the intermediate variable is:\n",
        "  $z = W^{(1)}x$.\n",
        "* Here  $ W^{(1)}$ is the weight parameter of the hidden layer."
      ],
      "metadata": {
        "id": "u5QunzGtN5cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "kRZBzuOZPg8s"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.randn(4,4)"
      ],
      "metadata": {
        "id": "0RI9_yM9TioK"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3,4,requires_grad=True)\n",
        "w_1 = torch.rand(4,3,requires_grad=True)\n",
        "z = torch.matmul(w_1,x)\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soBojpaePo8x",
        "outputId": "04e0aece-04b5-4bba-8c7f-f3ab45610c9c"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4196, 1.0340, 0.7025, 0.7207],\n",
              "        [0.6880, 1.4145, 0.8733, 1.0308],\n",
              "        [0.3399, 1.3209, 1.0559, 0.8510],\n",
              "        [0.7494, 1.3893, 0.7735, 1.0138]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* After running intermiadiate variable $z$ through activation function $Φ$ we obtain our hidden activation vector of length $h$:\n",
        "\n",
        "$h = Φ (z)$."
      ],
      "metadata": {
        "id": "YUqoQ0y6Qca8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(X):\n",
        "  return torch.max(torch.tensor(0.0),X)"
      ],
      "metadata": {
        "id": "I-d2odxwRMDU"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = relu(z)\n",
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QI-5LYQARXn9",
        "outputId": "e3f4a7c5-a9e3-4aa8-94ce-ea3dbe3391b2"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4196, 1.0340, 0.7025, 0.7207],\n",
              "        [0.6880, 1.4145, 0.8733, 1.0308],\n",
              "        [0.3399, 1.3209, 1.0559, 0.8510],\n",
              "        [0.7494, 1.3893, 0.7735, 1.0138]], grad_fn=<MaximumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The hidden layer output $h$ is also an intermediate variable.\n",
        "* Assumng that the parameters of the output layer posses only weight of $ W^{(2)}$, we can obtain an output layer variable with a vector of length q:\n",
        "   \n",
        "   $\n",
        "   o =  W^{(2)} h\n",
        "   $"
      ],
      "metadata": {
        "id": "coxIkfsHSgwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w_2 = torch.rand(4,4,requires_grad=True)\n",
        "o = torch.matmul(w_2,h)\n",
        "o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wpxxZqPTERd",
        "outputId": "0dce0c35-4945-4ef6-a83f-e00eed5b917a"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.4176, 3.3797, 2.2487, 2.3617],\n",
              "        [0.7570, 1.7180, 1.1118, 1.2115],\n",
              "        [1.0001, 2.5503, 1.7463, 1.7506],\n",
              "        [0.7228, 1.9312, 1.3586, 1.3217]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Assuming the loss function $l$ and the example label is $y$, we can can calculate the loss term for a single data example:\n",
        "  $L = l(o,y)$"
      ],
      "metadata": {
        "id": "tteTuL1UTxEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(y_true,y_hat):\n",
        "  ##ensuring values of y_hat are positive for log\n",
        "  #y_hat_clipped = torch.clamp(y_hat,min=1e-8) #avoids log(0)\n",
        "  return 0.5*torch.mean((y_hat-y_true)**2)"
      ],
      "metadata": {
        "id": "214G6UXeUFNB"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L=loss(y,o)\n",
        "L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pwjBmxHUMxm",
        "outputId": "31f248bf-2a74-49a2-a3e0-e6a18063ba6b"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.6228, grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Given the hyperparameter $λ$, the regularization term is:\n",
        "  \n",
        "  $s = \\frac{\\lambda}{2} \\left( \\|W^{(1)}\\|_F^2 + \\|W^{(2)}\\|_F^2 \\right)$\n",
        "\n",
        "* where the Frobenius norm of a matrix is simply the $l_2$.\n",
        "* Finally, the model's regularized loss on a given data example is:\n",
        "  $J = L + s$\n",
        "* We refer to $J$ as the $objective function$."
      ],
      "metadata": {
        "id": "ex5mLcUjUirv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##regularization term\n",
        "lambda_ = 0.1\n",
        "s = lambda_*0.5*(torch.norm(w_1,p='fro') + torch.norm(w_2,p='fro'))\n",
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9iHKLPRV2GC",
        "outputId": "a1634683-9a80-471b-9ea4-116b4ccb0d16"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2170, grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##objective function\n",
        "J =L + s\n",
        "J"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHprKdfJWiGF",
        "outputId": "41369868-44ff-4ac7-90ff-204b051df5ab"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.8398, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Computational Graph of Forward Propagation\n"
      ],
      "metadata": {
        "id": "rOmz8RARW5rg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7JPBcivzXUUo"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7363ce73"
      },
      "source": [
        "# Task\n",
        "Install `torchviz`, re-initialize the tensors `x`, `w_1`, and `w_2` with `requires_grad=True`, and then re-run the forward propagation to ensure the computation graph is traceable. Finally, use `torchviz.make_dot` to plot the computational graph of the objective function `J`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01b54807"
      },
      "source": [
        "## Install torchviz\n",
        "\n",
        "### Subtask:\n",
        "Install the torchviz library for visualizing PyTorch computation graphs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "423fa62e"
      },
      "source": [
        "**Reasoning**:\n",
        "To install the `torchviz` library as per the instructions, I will use `!pip install torchviz` in a code cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adbaa968"
      },
      "source": [
        "#get_ipython().system('pip install torchviz')"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchviz import make_dot\n",
        "\n",
        "# Plot the computational graph of J\n",
        "graph = make_dot(J, params={'x': x, 'w_1': w_1, 'w_2': w_2,})\n",
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "7Id7-nDLZQic",
        "outputId": "64261abe-13fd-499c-cb39-6ebdca6c52bd"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"402pt\" height=\"611pt\"\n viewBox=\"0.00 0.00 402.00 611.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 607)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-607 398,-607 398,4 -4,4\"/>\n<!-- 132354169887056 -->\n<g id=\"node1\" class=\"node\">\n<title>132354169887056</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"163.5,-31 109.5,-31 109.5,0 163.5,0 163.5,-31\"/>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 132354171641744 -->\n<g id=\"node2\" class=\"node\">\n<title>132354171641744</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"181,-86 92,-86 92,-67 181,-67 181,-86\"/>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 132354171641744&#45;&gt;132354169887056 -->\n<g id=\"edge20\" class=\"edge\">\n<title>132354171641744&#45;&gt;132354169887056</title>\n<path fill=\"none\" stroke=\"black\" d=\"M136.5,-66.79C136.5,-60.07 136.5,-50.4 136.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"140,-41.19 136.5,-31.19 133,-41.19 140,-41.19\"/>\n</g>\n<!-- 132354184085568 -->\n<g id=\"node3\" class=\"node\">\n<title>132354184085568</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"145,-141 56,-141 56,-122 145,-122 145,-141\"/>\n<text text-anchor=\"middle\" x=\"100.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 132354184085568&#45;&gt;132354171641744 -->\n<g id=\"edge1\" class=\"edge\">\n<title>132354184085568&#45;&gt;132354171641744</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106.44,-121.75C111.48,-114.34 118.84,-103.5 125.01,-94.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"127.94,-96.33 130.67,-86.09 122.15,-92.39 127.94,-96.33\"/>\n</g>\n<!-- 132354170208800 -->\n<g id=\"node4\" class=\"node\">\n<title>132354170208800</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"130,-196 35,-196 35,-177 130,-177 130,-196\"/>\n<text text-anchor=\"middle\" x=\"82.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n</g>\n<!-- 132354170208800&#45;&gt;132354184085568 -->\n<g id=\"edge2\" class=\"edge\">\n<title>132354170208800&#45;&gt;132354184085568</title>\n<path fill=\"none\" stroke=\"black\" d=\"M85.47,-176.75C87.86,-169.72 91.29,-159.62 94.27,-150.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"97.68,-151.68 97.58,-141.09 91.05,-149.43 97.68,-151.68\"/>\n</g>\n<!-- 132354170208944 -->\n<g id=\"node5\" class=\"node\">\n<title>132354170208944</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"119,-251 30,-251 30,-232 119,-232 119,-251\"/>\n<text text-anchor=\"middle\" x=\"74.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 132354170208944&#45;&gt;132354170208800 -->\n<g id=\"edge3\" class=\"edge\">\n<title>132354170208944&#45;&gt;132354170208800</title>\n<path fill=\"none\" stroke=\"black\" d=\"M75.82,-231.75C76.87,-224.8 78.37,-214.85 79.69,-206.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"83.17,-206.5 81.2,-196.09 76.25,-205.45 83.17,-206.5\"/>\n</g>\n<!-- 132354170209040 -->\n<g id=\"node6\" class=\"node\">\n<title>132354170209040</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"103,-306 14,-306 14,-287 103,-287 103,-306\"/>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n</g>\n<!-- 132354170209040&#45;&gt;132354170208944 -->\n<g id=\"edge4\" class=\"edge\">\n<title>132354170209040&#45;&gt;132354170208944</title>\n<path fill=\"none\" stroke=\"black\" d=\"M61.14,-286.75C63.26,-279.72 66.31,-269.62 68.96,-260.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"72.37,-261.67 71.91,-251.09 65.67,-259.65 72.37,-261.67\"/>\n</g>\n<!-- 132354170209136 -->\n<g id=\"node7\" class=\"node\">\n<title>132354170209136</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"98,-361 15,-361 15,-342 98,-342 98,-361\"/>\n<text text-anchor=\"middle\" x=\"56.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">MmBackward0</text>\n</g>\n<!-- 132354170209136&#45;&gt;132354170209040 -->\n<g id=\"edge5\" class=\"edge\">\n<title>132354170209136&#45;&gt;132354170209040</title>\n<path fill=\"none\" stroke=\"black\" d=\"M56.83,-341.75C57.09,-334.8 57.47,-324.85 57.8,-316.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"61.3,-316.21 58.18,-306.09 54.3,-315.95 61.3,-316.21\"/>\n</g>\n<!-- 132354170209232 -->\n<g id=\"node8\" class=\"node\">\n<title>132354170209232</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"232,-416 131,-416 131,-397 232,-397 232,-416\"/>\n<text text-anchor=\"middle\" x=\"181.5\" y=\"-404\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 132354170209232&#45;&gt;132354170209136 -->\n<g id=\"edge6\" class=\"edge\">\n<title>132354170209232&#45;&gt;132354170209136</title>\n<path fill=\"none\" stroke=\"black\" d=\"M161.42,-396.98C141.13,-388.38 109.54,-374.99 86.33,-365.15\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"87.52,-361.85 76.95,-361.17 84.79,-368.3 87.52,-361.85\"/>\n</g>\n<!-- 132354170209184 -->\n<g id=\"node19\" class=\"node\">\n<title>132354170209184</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"283,-361 116,-361 116,-342 283,-342 283,-361\"/>\n<text text-anchor=\"middle\" x=\"199.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">LinalgVectorNormBackward0</text>\n</g>\n<!-- 132354170209232&#45;&gt;132354170209184 -->\n<g id=\"edge19\" class=\"edge\">\n<title>132354170209232&#45;&gt;132354170209184</title>\n<path fill=\"none\" stroke=\"black\" d=\"M184.47,-396.75C186.86,-389.72 190.29,-379.62 193.27,-370.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"196.68,-371.68 196.58,-361.09 190.05,-369.43 196.68,-371.68\"/>\n</g>\n<!-- 132354171723104 -->\n<g id=\"node9\" class=\"node\">\n<title>132354171723104</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"209,-482 150,-482 150,-452 209,-452 209,-482\"/>\n<text text-anchor=\"middle\" x=\"179.5\" y=\"-470\" font-family=\"monospace\" font-size=\"10.00\">w_2</text>\n<text text-anchor=\"middle\" x=\"179.5\" y=\"-459\" font-family=\"monospace\" font-size=\"10.00\"> (4, 4)</text>\n</g>\n<!-- 132354171723104&#45;&gt;132354170209232 -->\n<g id=\"edge7\" class=\"edge\">\n<title>132354171723104&#45;&gt;132354170209232</title>\n<path fill=\"none\" stroke=\"black\" d=\"M179.98,-451.84C180.24,-444.21 180.57,-434.7 180.85,-426.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"184.36,-426.38 181.2,-416.27 177.36,-426.14 184.36,-426.38\"/>\n</g>\n<!-- 132354170209280 -->\n<g id=\"node10\" class=\"node\">\n<title>132354170209280</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"113,-416 0,-416 0,-397 113,-397 113,-416\"/>\n<text text-anchor=\"middle\" x=\"56.5\" y=\"-404\" font-family=\"monospace\" font-size=\"10.00\">MaximumBackward0</text>\n</g>\n<!-- 132354170209280&#45;&gt;132354170209136 -->\n<g id=\"edge8\" class=\"edge\">\n<title>132354170209280&#45;&gt;132354170209136</title>\n<path fill=\"none\" stroke=\"black\" d=\"M56.5,-396.75C56.5,-389.8 56.5,-379.85 56.5,-371.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"60,-371.09 56.5,-361.09 53,-371.09 60,-371.09\"/>\n</g>\n<!-- 132354170209424 -->\n<g id=\"node11\" class=\"node\">\n<title>132354170209424</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"115,-476.5 32,-476.5 32,-457.5 115,-457.5 115,-476.5\"/>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-464.5\" font-family=\"monospace\" font-size=\"10.00\">MmBackward0</text>\n</g>\n<!-- 132354170209424&#45;&gt;132354170209280 -->\n<g id=\"edge9\" class=\"edge\">\n<title>132354170209424&#45;&gt;132354170209280</title>\n<path fill=\"none\" stroke=\"black\" d=\"M70.99,-457.37C68.61,-449.16 64.94,-436.54 61.89,-426.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"65.17,-424.79 59.02,-416.17 58.45,-426.75 65.17,-424.79\"/>\n</g>\n<!-- 132354170209472 -->\n<g id=\"node12\" class=\"node\">\n<title>132354170209472</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"302,-537 201,-537 201,-518 302,-518 302,-537\"/>\n<text text-anchor=\"middle\" x=\"251.5\" y=\"-525\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 132354170209472&#45;&gt;132354170209424 -->\n<g id=\"edge10\" class=\"edge\">\n<title>132354170209472&#45;&gt;132354170209424</title>\n<path fill=\"none\" stroke=\"black\" d=\"M225.62,-517.99C194.9,-507.9 143.52,-491.01 109.08,-479.69\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"110.01,-476.31 99.41,-476.52 107.82,-482.96 110.01,-476.31\"/>\n</g>\n<!-- 132354170209088 -->\n<g id=\"node18\" class=\"node\">\n<title>132354170209088</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"394,-476.5 227,-476.5 227,-457.5 394,-457.5 394,-476.5\"/>\n<text text-anchor=\"middle\" x=\"310.5\" y=\"-464.5\" font-family=\"monospace\" font-size=\"10.00\">LinalgVectorNormBackward0</text>\n</g>\n<!-- 132354170209472&#45;&gt;132354170209088 -->\n<g id=\"edge17\" class=\"edge\">\n<title>132354170209472&#45;&gt;132354170209088</title>\n<path fill=\"none\" stroke=\"black\" d=\"M260.21,-517.87C269.18,-508.97 283.38,-494.89 294.41,-483.95\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"297.12,-486.19 301.76,-476.67 292.19,-481.22 297.12,-486.19\"/>\n</g>\n<!-- 132354170422368 -->\n<g id=\"node13\" class=\"node\">\n<title>132354170422368</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"281,-603 222,-603 222,-573 281,-573 281,-603\"/>\n<text text-anchor=\"middle\" x=\"251.5\" y=\"-591\" font-family=\"monospace\" font-size=\"10.00\">w_1</text>\n<text text-anchor=\"middle\" x=\"251.5\" y=\"-580\" font-family=\"monospace\" font-size=\"10.00\"> (4, 3)</text>\n</g>\n<!-- 132354170422368&#45;&gt;132354170209472 -->\n<g id=\"edge11\" class=\"edge\">\n<title>132354170422368&#45;&gt;132354170209472</title>\n<path fill=\"none\" stroke=\"black\" d=\"M251.5,-572.84C251.5,-565.21 251.5,-555.7 251.5,-547.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"255,-547.27 251.5,-537.27 248,-547.27 255,-547.27\"/>\n</g>\n<!-- 132354170209520 -->\n<g id=\"node14\" class=\"node\">\n<title>132354170209520</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"124,-537 23,-537 23,-518 124,-518 124,-537\"/>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-525\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 132354170209520&#45;&gt;132354170209424 -->\n<g id=\"edge12\" class=\"edge\">\n<title>132354170209520&#45;&gt;132354170209424</title>\n<path fill=\"none\" stroke=\"black\" d=\"M73.5,-517.87C73.5,-509.75 73.5,-497.31 73.5,-486.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"77,-486.67 73.5,-476.67 70,-486.67 77,-486.67\"/>\n</g>\n<!-- 132354170617152 -->\n<g id=\"node15\" class=\"node\">\n<title>132354170617152</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"103,-603 44,-603 44,-573 103,-573 103,-603\"/>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-591\" font-family=\"monospace\" font-size=\"10.00\">x</text>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-580\" font-family=\"monospace\" font-size=\"10.00\"> (3, 4)</text>\n</g>\n<!-- 132354170617152&#45;&gt;132354170209520 -->\n<g id=\"edge13\" class=\"edge\">\n<title>132354170617152&#45;&gt;132354170209520</title>\n<path fill=\"none\" stroke=\"black\" d=\"M73.5,-572.84C73.5,-565.21 73.5,-555.7 73.5,-547.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"77,-547.27 73.5,-537.27 70,-547.27 77,-547.27\"/>\n</g>\n<!-- 132354170208560 -->\n<g id=\"node16\" class=\"node\">\n<title>132354170208560</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"241,-196 152,-196 152,-177 241,-177 241,-196\"/>\n<text text-anchor=\"middle\" x=\"196.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 132354170208560&#45;&gt;132354171641744 -->\n<g id=\"edge14\" class=\"edge\">\n<title>132354170208560&#45;&gt;132354171641744</title>\n<path fill=\"none\" stroke=\"black\" d=\"M191.59,-176.66C181.7,-158.85 159.2,-118.37 146.23,-95.01\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"149.23,-93.2 141.31,-86.16 143.11,-96.6 149.23,-93.2\"/>\n</g>\n<!-- 132354170705504 -->\n<g id=\"node17\" class=\"node\">\n<title>132354170705504</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"244,-306 155,-306 155,-287 244,-287 244,-306\"/>\n<text text-anchor=\"middle\" x=\"199.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 132354170705504&#45;&gt;132354170208560 -->\n<g id=\"edge15\" class=\"edge\">\n<title>132354170705504&#45;&gt;132354170208560</title>\n<path fill=\"none\" stroke=\"black\" d=\"M199.25,-286.66C198.77,-269.17 197.68,-229.8 197.02,-206.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"200.52,-206.06 196.74,-196.16 193.52,-206.25 200.52,-206.06\"/>\n</g>\n<!-- 132354170209088&#45;&gt;132354170705504 -->\n<g id=\"edge16\" class=\"edge\">\n<title>132354170209088&#45;&gt;132354170705504</title>\n<path fill=\"none\" stroke=\"black\" d=\"M311.7,-457.47C314.25,-435.82 318.03,-377.91 291.5,-342 280.12,-326.59 261.96,-316.26 244.78,-309.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"245.97,-306.18 235.38,-306.05 243.58,-312.76 245.97,-306.18\"/>\n</g>\n<!-- 132354170209184&#45;&gt;132354170705504 -->\n<g id=\"edge18\" class=\"edge\">\n<title>132354170209184&#45;&gt;132354170705504</title>\n<path fill=\"none\" stroke=\"black\" d=\"M199.5,-341.75C199.5,-334.8 199.5,-324.85 199.5,-316.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"203,-316.09 199.5,-306.09 196,-316.09 203,-316.09\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x78601b4cc110>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 BackPropagation"
      ],
      "metadata": {
        "id": "l7zp3BC0aoFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Backprogation referes to the method of calculating the gradients of neural networks parameters.\n",
        "* This method transverses the network transverses the network in reverse order, from output to the input layer, according the **chain rule** from calculus.\n",
        "* The algorithm stores any intermediate variables required while calculating the gradient with respect to some parameters.\n",
        "* Assume that we have functions $Y=f(x)$ and $Z=g(x)$, in which the input and output X,Y,Z are tensors of random shapes.\n",
        "* By using chain rule,we can compute the derivative of $Z$ with respect to $X$ via:\n",
        "  $\\frac{\\partial Z}{\\partial X} = \\frac{\\partial Z}{\\partial Y} \\frac{\\partial Y}{\\partial X}$\n",
        "\n",
        "* Here we use the prod operator to multiply its arguments after necessary operations.\n",
        "* Recall that the parameters of the simple forward pass we previously attempted,its parameters are $W^{(1)}$ and $W^{(2)}$.\n",
        "* The objective of backpropagation is to calculate the gradients $\\frac{\\partial J}{\\partial W^{(1)}} \\quad \\text{and} \\quad \\frac{\\partial J}{\\partial W^{(2)}}$.\n",
        "* To accomplish this, we apply chain rule and calculate,in turn the gradients of each intermediate variable and parameter.\n",
        "* First we calculate the gradient of the objective function $J=L+s$ with respect to the loss term $L$ and the regularization term $S$:\n",
        "  $\\frac{\\partial J}{\\partial L} = 1 \\quad \\text{and} \\quad \\frac{\\partial J}{\\partial s} = 1$\n",
        "  \n"
      ],
      "metadata": {
        "id": "AX4rlsOWarVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dj_dl =1\n",
        "dj_ds = 1\n"
      ],
      "metadata": {
        "id": "_X1sSuUOfOHM"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Next we compute the gradient of the objective function with respect to  variable of the output layer $o$ according to chain rule:\n",
        "  $\\frac{\\partial J}{\\partial o} = \\frac{\\partial J}{\\partial L} \\frac{\\partial L}{\\partial o} = \\frac{\\partial L}{\\partial o} \\in \\mathbb{R}^q$"
      ],
      "metadata": {
        "id": "3an476JrfZbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = o.numel()"
      ],
      "metadata": {
        "id": "L2sxf8hHnhpf"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl_do = ((o-y)*2)/N\n",
        "dl_do"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noBB_XjSf1Jn",
        "outputId": "e09333d0-ea6d-46f6-aeb7-ec94c0d85f4d"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2308,  0.4037,  0.2244,  0.1764],\n",
              "        [ 0.1148,  0.2971,  0.2370, -0.0182],\n",
              "        [ 0.0774,  0.1832,  0.1737,  0.2016],\n",
              "        [ 0.1187,  0.2212,  0.3522,  0.2414]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dj_do = dj_dl*dl_do\n",
        "dj_do"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60A0iWfFhaa4",
        "outputId": "45ee6b3c-2c08-4dbf-b9a6-eb95da4eaa11"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2308,  0.4037,  0.2244,  0.1764],\n",
              "        [ 0.1148,  0.2971,  0.2370, -0.0182],\n",
              "        [ 0.0774,  0.1832,  0.1737,  0.2016],\n",
              "        [ 0.1187,  0.2212,  0.3522,  0.2414]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Next we calculate the gradients of the regularization term with respect to both parameters:  \n",
        "  $\\frac{\\partial s}{\\partial W^{(1)}} = \\lambda W^{(1)} \\quad \\text{and} \\quad \\frac{\\partial s}{\\partial W^{(2)}} = \\lambda W^{(2)}$"
      ],
      "metadata": {
        "id": "h51XnLxzcDxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_dw1 = lambda_*w_1\n",
        "ds_dw2 = lambda_*w_2\n",
        "ds_dw1,ds_dw2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iDgS627iPsT",
        "outputId": "dd9b8ac7-d25e-4d5a-fc28-6fb3b6fccff6"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0398, 0.0382, 0.0593],\n",
              "         [0.0251, 0.0647, 0.0997],\n",
              "         [0.0990, 0.0260, 0.0480],\n",
              "         [0.0148, 0.0765, 0.0951]], grad_fn=<MulBackward0>),\n",
              " tensor([[0.0530, 0.0658, 0.0759, 0.0646],\n",
              "         [0.0513, 0.0243, 0.0217, 0.0402],\n",
              "         [0.0007, 0.0153, 0.0975, 0.0748],\n",
              "         [0.0150, 0.0368, 0.0726, 0.0213]], grad_fn=<MulBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Now we are able to calculate the gradient $\\frac{\\partial J}{\\partial W^{(2)}} $ of the model parameters closest to the output layer. Using chain rule yields:\n",
        "  $\\frac{\\partial J}{\\partial W^{(2)}} = \\frac{\\partial J}{\\partial o} \\frac{\\partial o}{\\partial W^{(2)}} + \\frac{\\partial J}{\\partial s} \\frac{\\partial s}{\\partial W^{(2)}} = \\frac{\\partial L}{\\partial o} h^\\top + \\lambda W^{(2)}$"
      ],
      "metadata": {
        "id": "sLwjYnqPi5It"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dj_dw2 = dj_do*h.T + lambda_*w_2\n",
        "dj_dw2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHmCpKKobype",
        "outputId": "ae96192c-e4ee-44dc-bb0c-95d582e7617d"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0439,  0.3436,  0.1522,  0.1968],\n",
              "        [ 0.1699,  0.4446,  0.3346,  0.0149],\n",
              "        [ 0.0551,  0.1753,  0.2809,  0.2307],\n",
              "        [ 0.1005,  0.2648,  0.3724,  0.2661]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* To obtain the gradients with respect to $W^{(1)}$ we need to continue backpropagation along the output layer to hidden layer.\n",
        "* The gradient with respect to hidden layer output $\\frac{\\partial J}{\\partial h} \\in \\mathbb{R}^h$ is given by.\n",
        "  $\\frac{\\partial J}{\\partial h} = \\frac{\\partial J}{\\partial o} \\frac{\\partial o}{\\partial h} = (W^{(2)})^\\top \\frac{\\partial J}{\\partial o}$"
      ],
      "metadata": {
        "id": "Z-_p-KWjlYGk"
      }
    }
  ]
}