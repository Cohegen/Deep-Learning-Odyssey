- In this directory we go through the basics of deep learning like probability &stats,calculus and Linear Algebra
- As we proceed we'll come to realise that calculus and linear algebra are core deep learning principles

  ## LINEAR ALGEBRA

  ![Output examples](https://github.com/Cohegen/Deep-Learning-Odyssey/blob/main/assets/linear_algebra.gif)


- Since data in deep learning are embedded and manipulated in vectors and matrices linear algebra is crucial.

## Calculus
 ![Output examples](https://github.com/Cohegen/Deep-Learning-Odyssey/blob/main/assets/calculus.gif)

 - Most deep learning models are not always correct, they  at majority at times give biased predictions. But what can we do to minimize this error we use a concept called `bacckpropagation` where we differiantiate the loss function with respect to tis parameters.
 - Look at the `4_Calculus.ipynb` and `5_Automatic_Differentiation.ipynb` to understand the concepts of calculus sued in machine learning.

## Probability & Stats
 ![Output examples](https://github.com/Cohegen/Deep-Learning-Odyssey/blob/main/assets/probability.gif)
- Deep learning models often produce multiple possible outputs, and to determine the most likely one, they assign confidence scores (or probabilities) to each element of the output vector. These scores represent the modelâ€™s estimated likelihood of each possible output.
